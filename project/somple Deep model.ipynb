{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c258f844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6af05e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_result(y_true,y_pred):\n",
    "  cm = confusion_matrix(y_true, y_pred)\n",
    "  df_cm = pd.DataFrame(cm, range(2), range(2))\n",
    "  plt.figure(figsize=(10,7))\n",
    "  sn.set(font_scale=1) \n",
    "  sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 20},fmt=\"d\",cmap=\"YlGnBu\") # font size\n",
    "  from sklearn.metrics import classification_report\n",
    "  from sklearn.metrics import f1_score,recall_score,precision_score\n",
    "  target_names = ['class 0', 'class 1']\n",
    "  print(\"f1_score \"+\" is :{}%\".format(f1_score(y_true=y_true , y_pred= y_pred)))\n",
    "  print(\"recall_score \"+\" is :{}%\".format(recall_score(y_true=y_true , y_pred= y_pred)))\n",
    "  print(\"precision_score \"+\" is :{}%\".format(precision_score(y_true=y_true , y_pred= y_pred)))\n",
    "  print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4ba0253",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/EDA.csv')\n",
    "data = data.iloc[: , 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "371a6ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sale</th>\n",
       "      <th>nb_clicks_1week</th>\n",
       "      <th>product_price</th>\n",
       "      <th>product_age_group</th>\n",
       "      <th>device_type</th>\n",
       "      <th>audience_id</th>\n",
       "      <th>product_gender</th>\n",
       "      <th>product_brand</th>\n",
       "      <th>product_category(1)</th>\n",
       "      <th>product_category(2)</th>\n",
       "      <th>...</th>\n",
       "      <th>product_category(5)</th>\n",
       "      <th>product_category(6)</th>\n",
       "      <th>product_country</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>partner_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>day_time_category</th>\n",
       "      <th>tree_encode</th>\n",
       "      <th>category_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>439.389006</td>\n",
       "      <td>85.491137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>439.389006</td>\n",
       "      <td>85.491137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>439.389006</td>\n",
       "      <td>85.491137</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>439.389006</td>\n",
       "      <td>85.491137</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>439.389006</td>\n",
       "      <td>85.491137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sale  nb_clicks_1week  product_price  product_age_group  device_type  \\\n",
       "0   0.0       439.389006      85.491137                  0            0   \n",
       "1   0.0       439.389006      85.491137                  0            0   \n",
       "2   0.0       439.389006      85.491137                  1            1   \n",
       "3   0.0       439.389006      85.491137                  0            2   \n",
       "4   0.0       439.389006      85.491137                  1            0   \n",
       "\n",
       "   audience_id  product_gender  product_brand  product_category(1)  \\\n",
       "0            0               0              0                    0   \n",
       "1            0               0              0                    0   \n",
       "2            0               1              1                    1   \n",
       "3            0               0              0                    0   \n",
       "4            0               2              2                    2   \n",
       "\n",
       "   product_category(2)  ...  product_category(5)  product_category(6)  \\\n",
       "0                    0  ...                    0                    0   \n",
       "1                    0  ...                    0                    0   \n",
       "2                    1  ...                    0                    0   \n",
       "3                    0  ...                    0                    0   \n",
       "4                    2  ...                    0                    0   \n",
       "\n",
       "   product_country  product_id  product_title  partner_id  user_id  \\\n",
       "0                0           0              0           0        0   \n",
       "1                0           1              0           0        1   \n",
       "2                1           2              1           1        2   \n",
       "3                0           3              0           0        3   \n",
       "4                2           4              2           2        4   \n",
       "\n",
       "   day_time_category  tree_encode  category_encode  \n",
       "0                  4            6                0  \n",
       "1                  1            6                0  \n",
       "2                 16           12                3  \n",
       "3                 20            6                0  \n",
       "4                 20           18               15  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data\n",
    "df = df.drop(columns = [\"SalesAmountInEuro\",\"time_delay_for_conversion\",\"click_timestamp\",\"day\",\"day_time\"])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178990c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14348/2868579080.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# scaling the train and test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nb_clicks_1week'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nb_clicks_1week'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sale'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sale'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"product_price\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "# scaling the train and test set\n",
    "df['nb_clicks_1week'] = sc.fit_transform(df['nb_clicks_1week'])\n",
    "y = df['Sale'].to_numpy()\n",
    "X = df.drop(['Sale',\"product_price\"], axis=1)\n",
    "X[\"nb_clicks_1week\"]=(X[\"nb_clicks_1week\"]-X[\"nb_clicks_1week\"].mean())/X[\"nb_clicks_1week\"].std()\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83d1b095",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s_nn = nn.Sequential(\n",
    "        nn.Linear(20,128),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(128,64),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(64,32),\n",
    "        nn.LeakyReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "        nn.Linear(32,16),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(16,8),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Linear(8,1),\n",
    "        nn.Sigmoid()\n",
    "\n",
    "    )\n",
    "for i in range(20):\n",
    "    X, y = shuffle(X, y, random_state=i)\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "s_nn.to(device)\n",
    "\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(s_nn.parameters(),lr=0.00001)\n",
    "\n",
    "\n",
    "dataset = TensorDataset(torch.unsqueeze(torch.Tensor(X.to_numpy()),1),torch.Tensor(y))\n",
    "train_subset, val_subset = torch.utils.data.random_split(\n",
    "        dataset, [60000, 40000], generator=torch.Generator().manual_seed(1))\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "NUMBER_OF_EPOCHS = 50\n",
    "train_loader = DataLoader(dataset=train_subset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(dataset=val_subset, shuffle=False, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72608d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 - train Loss: 2.117e+03 - train Acc: 85.61%: 100%|â–ˆ| 235/235 [00:01<00:0\n",
      "epoch 0 - val Loss: 7.322e+00 - val Acc: 86.25%: 100%|â–ˆ| 157/157 [00:00<00:00, 2\n",
      "epoch 1 - train Loss: 1.621e+03 - train Acc: 85.80%: 100%|â–ˆ| 235/235 [00:01<00:0\n",
      "epoch 1 - val Loss: 2.501e+00 - val Acc: 86.28%: 100%|â–ˆ| 157/157 [00:00<00:00, 2\n",
      "epoch 2 - train Loss: 8.498e+02 - train Acc: 85.86%: 100%|â–ˆ| 235/235 [00:02<00:0\n",
      "epoch 2 - val Loss: 8.239e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, 1\n",
      "epoch 3 - train Loss: 3.752e+02 - train Acc: 86.27%: 100%|â–ˆ| 235/235 [00:02<00:0\n",
      "epoch 3 - val Loss: 5.501e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, 1\n",
      "epoch 4 - train Loss: 2.291e+02 - train Acc: 86.31%: 100%|â–ˆ| 235/235 [00:02<00:0\n",
      "epoch 4 - val Loss: 4.871e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, 1\n",
      "epoch 5 - train Loss: 1.818e+02 - train Acc: 86.33%: 100%|â–ˆ| 235/235 [00:02<00:0\n",
      "epoch 5 - val Loss: 4.735e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, 1\n",
      "epoch 6 - train Loss: 1.572e+02 - train Acc: 86.34%: 100%|â–ˆ| 235/235 [00:02<00:0\n",
      "epoch 6 - val Loss: 4.676e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, 1\n",
      "epoch 7 - train Loss: 1.449e+02 - train Acc: 86.35%: 100%|â–ˆ| 235/235 [00:02<00:0\n",
      "epoch 7 - val Loss: 4.643e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, 1\n",
      "epoch 8 - train Loss: 1.409e+02 - train Acc: 86.35%: 100%|â–ˆ| 235/235 [00:02<00:0\n",
      "epoch 8 - val Loss: 4.617e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, 9\n",
      "epoch 9 - train Loss: 1.392e+02 - train Acc: 86.35%: 100%|â–ˆ| 235/235 [00:03<00:0\n",
      "epoch 9 - val Loss: 4.587e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, 1\n",
      "epoch 10 - train Loss: 1.336e+02 - train Acc: 86.36%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 10 - val Loss: 4.580e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 11 - train Loss: 1.325e+02 - train Acc: 86.35%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 11 - val Loss: 4.557e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 12 - train Loss: 1.290e+02 - train Acc: 86.36%: 100%|â–ˆ| 235/235 [00:02<00:\n",
      "epoch 12 - val Loss: 4.538e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 13 - train Loss: 1.289e+02 - train Acc: 86.36%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 13 - val Loss: 4.533e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 14 - train Loss: 1.275e+02 - train Acc: 86.36%: 100%|â–ˆ| 235/235 [00:02<00:\n",
      "epoch 14 - val Loss: 4.521e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 15 - train Loss: 1.258e+02 - train Acc: 86.36%: 100%|â–ˆ| 235/235 [00:02<00:\n",
      "epoch 15 - val Loss: 4.511e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 16 - train Loss: 1.236e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 16 - val Loss: 4.511e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 17 - train Loss: 1.227e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 17 - val Loss: 4.499e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 18 - train Loss: 1.236e+02 - train Acc: 86.36%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 18 - val Loss: 4.496e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 19 - train Loss: 1.226e+02 - train Acc: 86.36%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 19 - val Loss: 4.492e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 20 - train Loss: 1.214e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 20 - val Loss: 4.489e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 21 - train Loss: 1.202e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 21 - val Loss: 4.477e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 22 - train Loss: 1.202e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 22 - val Loss: 4.477e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 23 - train Loss: 1.202e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 23 - val Loss: 4.470e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 24 - train Loss: 1.201e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 24 - val Loss: 4.470e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 25 - train Loss: 1.199e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 25 - val Loss: 4.484e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 26 - train Loss: 1.196e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 26 - val Loss: 4.470e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 27 - train Loss: 1.191e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 27 - val Loss: 4.473e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 28 - train Loss: 1.191e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 28 - val Loss: 4.474e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 29 - train Loss: 1.187e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:02<00:\n",
      "epoch 29 - val Loss: 4.470e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 30 - train Loss: 1.182e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 30 - val Loss: 4.470e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 31 - train Loss: 1.190e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 31 - val Loss: 4.464e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 32 - train Loss: 1.182e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 32 - val Loss: 4.474e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 33 - train Loss: 1.179e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 33 - val Loss: 4.474e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 34 - train Loss: 1.178e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:02<00:\n",
      "epoch 34 - val Loss: 4.469e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 35 - train Loss: 1.174e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 35 - val Loss: 4.463e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 36 - train Loss: 1.169e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 36 - val Loss: 4.465e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 37 - train Loss: 1.175e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:02<00:\n",
      "epoch 37 - val Loss: 4.468e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 38 - train Loss: 1.169e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 38 - val Loss: 4.469e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 39 - train Loss: 1.171e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:02<00:\n",
      "epoch 39 - val Loss: 4.466e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 40 - train Loss: 1.166e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 40 - val Loss: 4.468e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 41 - train Loss: 1.168e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 41 - val Loss: 4.459e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 42 - train Loss: 1.163e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 42 - val Loss: 4.471e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 43 - train Loss: 1.162e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 43 - val Loss: 4.472e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 44 - train Loss: 1.165e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 44 - val Loss: 4.469e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 45 - train Loss: 1.162e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 45 - val Loss: 4.477e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 46 - train Loss: 1.160e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 46 - val Loss: 4.464e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 47 - train Loss: 1.164e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 47 - val Loss: 4.460e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 48 - train Loss: 1.165e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 48 - val Loss: 4.466e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n",
      "epoch 49 - train Loss: 1.159e+02 - train Acc: 86.37%: 100%|â–ˆ| 235/235 [00:03<00:\n",
      "epoch 49 - val Loss: 4.462e-01 - val Acc: 86.29%: 100%|â–ˆ| 157/157 [00:01<00:00, \n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "all_train_losses = []\n",
    "all_train_accuracy = []\n",
    "all_val_losses = []\n",
    "all_val_accuracy = []\n",
    "for epoch in range(NUMBER_OF_EPOCHS):\n",
    "    # training\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    acc_list = []\n",
    "    epoch_all = 0\n",
    "    s_nn.train()\n",
    "    with tqdm.tqdm(enumerate(train_loader), total=len(train_loader)) as pbar:\n",
    "        for i, (x, y) in pbar:\n",
    "            images , labels = x.to(device) , y.to(device,dtype = torch.float)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = s_nn(images)\n",
    "            outputs = outputs.squeeze(1)\n",
    "            labels = labels.unsqueeze(1)\n",
    "            loss = loss_function (outputs , labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # calculate accuracy\n",
    "            epoch_loss += outputs.shape[0] * loss.item()\n",
    "            epoch_all += labels.size(0)\n",
    "            predicted = torch.round(outputs)#.argmax(-1)#torch.max(outputs.data,1)[0]\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            #print(correct)\n",
    "            #acc_list.append(correct/total)\n",
    "            pbar.set_description(f'epoch {epoch } - train Loss: {epoch_loss / (i + 1):.3e} - train Acc: {correct * 100. / epoch_all:.2f}%')\n",
    "   # all_train_losses.append(epoch_loss/60000)\n",
    "    ##print(f'trainin loss : {epoch_loss/60000}')\n",
    "    #print(f'trainin acc : {mean(acc_list)}')\n",
    "    #all_train_accuracy.append(mean(acc_list))\n",
    "    loss_list = []\n",
    "    s_nn.eval() \n",
    "    with torch.no_grad():\n",
    "        main = []\n",
    "        pre = []\n",
    "        epoch_loss = 0\n",
    "        epoch_all = 0\n",
    "        correct = 0\n",
    "        corr = 0\n",
    "        tot = 0\n",
    "        with tqdm.tqdm(enumerate(val_loader), total=len(val_loader)) as pbar:\n",
    "            for i, (x, y) in pbar:\n",
    "                images , labels = x.to(device) , y.to(device,dtype = torch.float)\n",
    "                out = s_nn(images)\n",
    "                out = out.squeeze(1)\n",
    "                labels = labels.unsqueeze(1)\n",
    "                los = loss_function (out , labels).item()\n",
    "                main.append(labels)\n",
    "                \n",
    "                epoch_loss += los\n",
    "                loss_list.append(los)\n",
    "                predicts = torch.round(out)\n",
    "                pre.append(predicts)\n",
    "                epoch_all+=labels.size(0)\n",
    "                tot += labels.size(0)\n",
    "                correct += (predicts == labels).sum().item()\n",
    "                pbar.set_description(f'epoch {epoch } - val Loss: {epoch_loss / (i + 1):.3e} - val Acc: {correct * 100. / epoch_all:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70eae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_result(main,pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f14e7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import convertor as cvn\n",
    "convertor = cvn.ConvertorD(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
