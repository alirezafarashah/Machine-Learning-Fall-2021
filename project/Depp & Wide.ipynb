{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf858f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8783ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_result(y_true,y_pred):\n",
    "  cm = confusion_matrix(y_true, y_pred)\n",
    "  df_cm = pd.DataFrame(cm, range(2), range(2))\n",
    "  plt.figure(figsize=(10,7))\n",
    "  sn.set(font_scale=1) \n",
    "  sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 20},fmt=\"d\",cmap=\"YlGnBu\") # font size\n",
    "  from sklearn.metrics import classification_report\n",
    "  from sklearn.metrics import f1_score,recall_score,precision_score\n",
    "  target_names = ['class 0', 'class 1']\n",
    "  print(\"f1_score \"+\" is :{}%\".format(f1_score(y_true=y_true , y_pred= y_pred)))\n",
    "  print(\"recall_score \"+\" is :{}%\".format(recall_score(y_true=y_true , y_pred= y_pred)))\n",
    "  print(\"precision_score \"+\" is :{}%\".format(precision_score(y_true=y_true , y_pred= y_pred)))\n",
    "  print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04094536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sale</th>\n",
       "      <th>nb_clicks_1week</th>\n",
       "      <th>product_age_group</th>\n",
       "      <th>device_type</th>\n",
       "      <th>audience_id</th>\n",
       "      <th>product_gender</th>\n",
       "      <th>product_brand</th>\n",
       "      <th>product_category(1)</th>\n",
       "      <th>product_category(2)</th>\n",
       "      <th>product_category(3)</th>\n",
       "      <th>product_category(4)</th>\n",
       "      <th>product_category(5)</th>\n",
       "      <th>product_category(6)</th>\n",
       "      <th>product_country</th>\n",
       "      <th>product_id</th>\n",
       "      <th>partner_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>day_time_category</th>\n",
       "      <th>tree_encode</th>\n",
       "      <th>category_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>439.389006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>439.389006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>439.389006</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>439.389006</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>439.389006</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sale  nb_clicks_1week  product_age_group  device_type  audience_id  \\\n",
       "0   0.0       439.389006                  0            0            0   \n",
       "1   0.0       439.389006                  0            0            0   \n",
       "2   0.0       439.389006                  1            1            0   \n",
       "3   0.0       439.389006                  0            2            0   \n",
       "4   0.0       439.389006                  1            0            0   \n",
       "\n",
       "   product_gender  product_brand  product_category(1)  product_category(2)  \\\n",
       "0               0              0                    0                    0   \n",
       "1               0              0                    0                    0   \n",
       "2               1              1                    1                    1   \n",
       "3               0              0                    0                    0   \n",
       "4               2              2                    2                    2   \n",
       "\n",
       "   product_category(3)  product_category(4)  product_category(5)  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    1                    1                    0   \n",
       "\n",
       "   product_category(6)  product_country  product_id  partner_id  user_id  \\\n",
       "0                    0                0           0           0        0   \n",
       "1                    0                0           1           0        1   \n",
       "2                    0                1           2           1        2   \n",
       "3                    0                0           3           0        3   \n",
       "4                    0                2           4           2        4   \n",
       "\n",
       "   day_time_category  tree_encode  category_encode  \n",
       "0                  4            6                0  \n",
       "1                  1            6                0  \n",
       "2                 16           12                3  \n",
       "3                 20            6                0  \n",
       "4                 20           18               15  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('datasets/EDA.csv')\n",
    "data = data.iloc[: , 1:]\n",
    "df = data\n",
    "df = df.drop(columns = [\"SalesAmountInEuro\",\"product_price\",\"time_delay_for_conversion\",\"click_timestamp\",\"product_title\",\"day\",\"day_time\"])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c9f0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f91d8702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sale</th>\n",
       "      <th>nb_clicks_1week</th>\n",
       "      <th>product_age_group</th>\n",
       "      <th>device_type</th>\n",
       "      <th>audience_id</th>\n",
       "      <th>product_gender</th>\n",
       "      <th>product_brand</th>\n",
       "      <th>product_category(1)</th>\n",
       "      <th>product_category(2)</th>\n",
       "      <th>product_category(3)</th>\n",
       "      <th>product_category(4)</th>\n",
       "      <th>product_category(5)</th>\n",
       "      <th>product_category(6)</th>\n",
       "      <th>product_country</th>\n",
       "      <th>partner_id</th>\n",
       "      <th>day_time_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.792466</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.792466</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.792466</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.792466</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.792466</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sale  nb_clicks_1week  product_age_group  device_type  audience_id  \\\n",
       "0   0.0         0.792466                  0            0            0   \n",
       "1   0.0         0.792466                  0            0            0   \n",
       "2   0.0         0.792466                  1            1            0   \n",
       "3   0.0         0.792466                  0            2            0   \n",
       "4   0.0         0.792466                  1            0            0   \n",
       "\n",
       "   product_gender  product_brand  product_category(1)  product_category(2)  \\\n",
       "0               0              0                    0                    0   \n",
       "1               0              0                    0                    0   \n",
       "2               1              1                    1                    1   \n",
       "3               0              0                    0                    0   \n",
       "4               2              2                    2                    2   \n",
       "\n",
       "   product_category(3)  product_category(4)  product_category(5)  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    1                    1                    0   \n",
       "\n",
       "   product_category(6)  product_country  partner_id  day_time_category  \n",
       "0                    0                0           0                  4  \n",
       "1                    0                0           0                  1  \n",
       "2                    0                1           1                 16  \n",
       "3                    0                0           0                 20  \n",
       "4                    0                2           2                 20  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns = [\"product_id\",\"user_id\",\"tree_encode\",\"category_encode\"])\n",
    "categorial_col = [\"product_age_group\",\"device_type\",\"audience_id\",\"partner_id\",\n",
    "                  \"product_gender\",\"product_category(1)\",\"product_category(2)\",\n",
    "                  \"product_category(3)\",\"product_category(4)\",\"product_category(5)\",\n",
    "                  \"product_category(6)\",\"product_country\",\"day_time_category\",\"product_brand\"]\n",
    "numerical_col = [\"nb_clicks_1week\"]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "df[numerical_col] = sc.fit_transform(df[numerical_col])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d316a59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 4, 3182, 183, 11, 22, 145, 699, 910, 442, 89, 17, 24, 4770]\n"
     ]
    }
   ],
   "source": [
    "categorial_featurs_dims = []\n",
    "for cat in categorial_col:\n",
    "    categorial_featurs_dims.append(df[cat].max()+1)\n",
    "print(categorial_featurs_dims)\n",
    "numerical_dim = len(numerical_col)\n",
    "emmbeded_hyper = 7\n",
    "MLP_dims = [2048,1024,512,256,128,64,32,16,8,4,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84ed8cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepWide(nn.Module):\n",
    "    def __init__(self,cat_F_dims,emmbeded_hyper,MLP_dims,numerical_dim):\n",
    "        super(DeepWide,self).__init__()\n",
    "        cat_dims = sum(cat_F_dims)\n",
    "        self.embeding = nn.Embedding(cat_dims, emmbeded_hyper)\n",
    "        input_dims = numerical_dim + len(cat_F_dims) * emmbeded_hyper\n",
    "        self.FXlayer = nn.Sequential(nn.Linear(input_dims, 1),nn.ReLU())\n",
    "        modules = []\n",
    "        for output in MLP_dims:\n",
    "            modules.append(nn.Linear(input_dims, output))\n",
    "            modules.append(nn.ReLU())\n",
    "            input_dims = output\n",
    "        self.MLP = nn.Sequential(*modules)\n",
    "        self.Flatten = nn.Flatten()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self,x1,x2):\n",
    "        embedded_output = torch.Tensor(self.embeding(x1.to(torch.int64)))\n",
    "        square_of_sum = torch.sum(embedded_output, axis=1) ** 2\n",
    "        sum_of_square = torch.sum(embedded_output ** 2, axis=1)\n",
    "        embedded_output2 = self.Flatten(embedded_output)\n",
    "        cated_input = torch.cat((embedded_output2, x2), -1 )\n",
    "        z = self.FXlayer(cated_input)\n",
    "        z+=self.MLP(cated_input)\n",
    "        z+=0.5 * (square_of_sum - sum_of_square).sum(1, keepdims=True)\n",
    "        return self.sigmoid(z).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c900271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 64729, 1.0: 10271})\n",
      "[64729 10271]\n",
      "[1.54490259e-05 9.73615033e-05]\n"
     ]
    }
   ],
   "source": [
    "y = df['Sale'].to_numpy()\n",
    "x1 = df[categorial_col].to_numpy()\n",
    "x2 = df[[\"nb_clicks_1week\"]].to_numpy()\n",
    "for i in range(20):\n",
    "    x1,x2, y = shuffle(x1,x2, y, random_state=i)\n",
    "x1_train,x1_test,x2_train,x2_test,y_train,y_test= train_test_split(x1,x2,\n",
    "                                                y,\n",
    "                                                test_size=0.25,\n",
    "                                                random_state=42,\n",
    "                                                shuffle=True)\n",
    "\n",
    "count = Counter(y_train)\n",
    "print(count)\n",
    "class_count=np.array([count[0],count[1]])\n",
    "print(class_count)\n",
    "weight=1./class_count\n",
    "print(weight)\n",
    "samples_weight = np.array([weight[int(t)] for t in y_train])\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "train_subset = torch.utils.data.TensorDataset(torch.Tensor(x1_train),torch.Tensor(x2_train),torch.Tensor(y_train))\n",
    "val_subset = torch.utils.data.TensorDataset(torch.Tensor(x1_test),torch.Tensor(x2_test),torch.Tensor(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c89a367",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepWide(categorial_featurs_dims,emmbeded_hyper,MLP_dims,numerical_dim)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "model.to(device);\n",
    "#dataset = TensorDataset(torch.Tensor(x1),torch.Tensor(x2),torch.Tensor(y))\n",
    "#train_subset, val_subset = torch.utils.data.random_split(\n",
    "#        dataset, [75000, 25000], generator=torch.Generator().manual_seed(45))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec393565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepWide(\n",
      "  (embeding): Embedding(10507, 7)\n",
      "  (FXlayer): Sequential(\n",
      "    (0): Linear(in_features=99, out_features=1, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (MLP): Sequential(\n",
      "    (0): Linear(in_features=99, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (13): ReLU()\n",
      "    (14): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (15): ReLU()\n",
      "    (16): Linear(in_features=16, out_features=8, bias=True)\n",
      "    (17): ReLU()\n",
      "    (18): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (19): ReLU()\n",
      "    (20): Linear(in_features=4, out_features=1, bias=True)\n",
      "    (21): ReLU()\n",
      "  )\n",
      "  (Flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "torch.Size([10507, 7])\n",
      "torch.Size([1, 99])\n",
      "torch.Size([1])\n",
      "torch.Size([2048, 99])\n",
      "torch.Size([2048])\n",
      "torch.Size([1024, 2048])\n",
      "torch.Size([1024])\n",
      "torch.Size([512, 1024])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32])\n",
      "torch.Size([16, 32])\n",
      "torch.Size([16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([8])\n",
      "torch.Size([4, 8])\n",
      "torch.Size([4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1])\n",
      "3076690\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.009)\n",
    "loss_function = nn.BCELoss()\n",
    "BATCH_SIZE = 256\n",
    "NUMBER_OF_EPOCHS = 40\n",
    "train_loader = DataLoader(dataset=train_subset, shuffle=False, batch_size=BATCH_SIZE)#,sampler = sampler)\n",
    "val_loader = DataLoader(dataset=val_subset, shuffle=False, batch_size=BATCH_SIZE)\n",
    "print(model)\n",
    "for parameter in model.parameters():\n",
    "    print(parameter.size())\n",
    "num_params = sum(param.numel() for param in model.parameters() if param.requires_grad)\n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d296bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 - train Loss: 3.217e+02 - train Acc: 63.54%:  70%|▋| 204/293 [00:11<00:0"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "all_train_losses = []\n",
    "all_train_accuracy = []\n",
    "all_val_losses = []\n",
    "all_val_accuracy = []\n",
    "for epoch in range(NUMBER_OF_EPOCHS):\n",
    "    # training\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    acc_list = []\n",
    "    epoch_all = 0\n",
    "    model.train()\n",
    "    with tqdm.tqdm(enumerate(train_loader), total=len(train_loader)) as pbar:\n",
    "        for i, (x1,x2, y) in pbar:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x1,x2)\n",
    "            loss = loss_function (outputs , y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += outputs.shape[0] * loss.item()\n",
    "            epoch_all += y.size(0)\n",
    "            predicted = torch.round(outputs)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            pbar.set_description(f'epoch {epoch } - train Loss: {epoch_loss / (i + 1):.3e} - train Acc: {correct * 100. / epoch_all:.2f}%')\n",
    "    loss_list = []\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        main = []\n",
    "        pre = []\n",
    "        epoch_loss = 0\n",
    "        epoch_all = 0\n",
    "        correct = 0\n",
    "        corr = 0\n",
    "        tot = 0\n",
    "        with tqdm.tqdm(enumerate(val_loader), total=len(val_loader)) as pbar:\n",
    "            for i, (x1,x2, y) in pbar:\n",
    "                out = model(x1,x2)\n",
    "                los = loss_function (out , y).item()\n",
    "                main.append(y)\n",
    "                epoch_loss += los\n",
    "                loss_list.append(los)\n",
    "                predicts = torch.round(out)\n",
    "                pre.append(predicts)\n",
    "                epoch_all+=y.size(0)\n",
    "                tot += y.size(0)\n",
    "                correct += (predicts == y).sum().item()\n",
    "                pbar.set_description(f'epoch {epoch } - val Loss: {epoch_loss / (i + 1):.3e} - val Acc: {correct * 100. / epoch_all:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "88bc8837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 39 - val Loss: 2.664e+00 - val Acc: 63.74%: 100%|█| 98/98 [00:01<00:00, 57\n"
     ]
    }
   ],
   "source": [
    "main = []\n",
    "pre = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    with tqdm.tqdm(enumerate(val_loader), total=len(val_loader)) as pbar:\n",
    "                for i, (x1,x2, y) in pbar:\n",
    "                    out = model(x1,x2)\n",
    "                    los = loss_function (out , y).item()\n",
    "                    main.append(y)\n",
    "                    epoch_loss += los\n",
    "                    loss_list.append(los)\n",
    "                    predicts = torch.round(out)\n",
    "                    pre.append(predicts)\n",
    "                    epoch_all+=y.size(0)\n",
    "                    tot += y.size(0)\n",
    "                    correct += (predicts == y).sum().item()\n",
    "                    pbar.set_description(f'epoch {epoch } - val Loss: {epoch_loss / (i + 1):.3e} - val Acc: {correct * 100. / epoch_all:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d125e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score  is :0.19474058280028428%\n",
      "recall_score  is :0.3233038348082596%\n",
      "precision_score  is :0.1393338418510043%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.87      0.69      0.77     21610\n",
      "     class 1       0.14      0.32      0.19      3390\n",
      "\n",
      "    accuracy                           0.64     25000\n",
      "   macro avg       0.50      0.51      0.48     25000\n",
      "weighted avg       0.77      0.64      0.69     25000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted = pre[0]\n",
    "true = main[0]\n",
    "for i in range(1,len(main)):\n",
    "    predicted = torch.cat((predicted, pre[i]), -1 )\n",
    "    true = torch.cat((true, main[i]), -1 )\n",
    "visualize_result(true,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2b622de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir models\n",
    "#plt.plot(range())\n",
    "torch.save(model.state_dict(), \"models/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e506694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepWide(\n",
       "  (embeding): Embedding(10507, 7)\n",
       "  (FXlayer): Sequential(\n",
       "    (0): Linear(in_features=99, out_features=1, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (MLP): Sequential(\n",
       "    (0): Linear(in_features=99, out_features=2048, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (11): ReLU()\n",
       "    (12): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (13): ReLU()\n",
       "    (14): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (15): ReLU()\n",
       "    (16): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (17): ReLU()\n",
       "    (18): Linear(in_features=8, out_features=4, bias=True)\n",
       "    (19): ReLU()\n",
       "    (20): Linear(in_features=4, out_features=1, bias=True)\n",
       "    (21): ReLU()\n",
       "  )\n",
       "  (Flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepWide(categorial_featurs_dims,emmbeded_hyper,MLP_dims,numerical_dim)\n",
    "model.load_state_dict(torch.load(\"models/model3\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10992591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepWide(\n",
      "  (embeding): Embedding(10507, 7)\n",
      "  (FXlayer): Sequential(\n",
      "    (0): Linear(in_features=99, out_features=1, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (MLP): Sequential(\n",
      "    (0): Linear(in_features=99, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (13): ReLU()\n",
      "    (14): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (15): ReLU()\n",
      "    (16): Linear(in_features=16, out_features=8, bias=True)\n",
      "    (17): ReLU()\n",
      "    (18): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (19): ReLU()\n",
      "    (20): Linear(in_features=4, out_features=1, bias=True)\n",
      "    (21): ReLU()\n",
      "  )\n",
      "  (Flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "parameters\n",
      "torch.Size([10507, 7])\n",
      "torch.Size([1, 99])\n",
      "torch.Size([1])\n",
      "torch.Size([2048, 99])\n",
      "torch.Size([2048])\n",
      "torch.Size([1024, 2048])\n",
      "torch.Size([1024])\n",
      "torch.Size([512, 1024])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([64, 128])\n",
      "torch.Size([64])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32])\n",
      "torch.Size([16, 32])\n",
      "torch.Size([16])\n",
      "torch.Size([8, 16])\n",
      "torch.Size([8])\n",
      "torch.Size([4, 8])\n",
      "torch.Size([4])\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1])\n",
      "3076690\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(\"parameters\")\n",
    "for parameter in model.parameters():\n",
    "    if parameter.requires_grad:\n",
    "        print(parameter.size())\n",
    "num_params = sum(param.numel() for param in model.parameters() if param.requires_grad)\n",
    "print(num_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f1ae846",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepWide2(nn.Module):\n",
    "    def __init__(self,cat_F_dims,emmbeded_hyper,MLP_dims,numerical_dim):\n",
    "        super(DeepWide2,self).__init__()\n",
    "        cat_dims = sum(cat_F_dims)\n",
    "        self.embeding = nn.Embedding(cat_dims, emmbeded_hyper)\n",
    "        input_dims = numerical_dim + len(cat_F_dims) * emmbeded_hyper\n",
    "        \n",
    "        modules = []\n",
    "        for output in MLP_dims:\n",
    "            modules.append(nn.Linear(input_dims, output))\n",
    "            modules.append(nn.ReLU())\n",
    "            input_dims = output\n",
    "        self.MLP = nn.Sequential(*modules)\n",
    "        self.Flatten = nn.Flatten()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        input_dims+= numerical_dim #+ len(cat_F_dims) * emmbeded_hyper\n",
    "        self.FXlayer = nn.Sequential(nn.Linear(input_dims, 1),nn.ReLU())\n",
    "    def forward(self,x1,x2):\n",
    "        embedded_output = torch.Tensor(self.embeding(x1.to(torch.int64)))\n",
    "        square_of_sum = torch.sum(embedded_output, axis=1) ** 2\n",
    "        sum_of_square = torch.sum(embedded_output ** 2, axis=1)\n",
    "        embedded_output2 = self.Flatten(embedded_output)\n",
    "        cated_input = torch.cat((embedded_output2, x2), -1 )\n",
    "        x3 = self.MLP(cated_input)\n",
    "        cated_input2 = torch.cat((cated_input,x3), -1 )\n",
    "        z = self.FXlayer(cated_input2)\n",
    "        z+=0.5 * (square_of_sum - sum_of_square).sum(1, keepdims=True)\n",
    "        return self.sigmoid(z).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c6d19d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_dim = len(numerical_col)\n",
    "emmbeded_hyper = 9\n",
    "MLP_dims = [2048,1024,512,256,128]\n",
    "model2 = DeepWide2(categorial_featurs_dims,emmbeded_hyper,MLP_dims,numerical_dim)\n",
    "optimizer2 = torch.optim.SGD(model2.parameters(),lr=0.005)\n",
    "loss_function2 = nn.BCELoss()\n",
    "BATCH_SIZE2 = 256\n",
    "NUMBER_OF_EPOCHS2 = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33dd6f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 - train Loss: 9.966e+03 - train Acc: 58.87%: 100%|█| 293/293 [00:19<00:0\n",
      "epoch 0 - val Loss: 8.369e+01 - val Acc: 16.00%: 100%|█| 98/98 [00:03<00:00, 31.\n",
      "epoch 1 - train Loss: 9.881e+03 - train Acc: 59.20%: 100%|█| 293/293 [00:20<00:0\n",
      "epoch 1 - val Loss: 8.369e+01 - val Acc: 16.00%: 100%|█| 98/98 [00:02<00:00, 41.\n",
      "epoch 2 - train Loss: 9.897e+03 - train Acc: 59.15%: 100%|█| 293/293 [00:20<00:0\n",
      "epoch 2 - val Loss: 8.369e+01 - val Acc: 16.00%: 100%|█| 98/98 [00:02<00:00, 42.\n",
      "epoch 3 - train Loss: 9.958e+03 - train Acc: 58.89%: 100%|█| 293/293 [00:20<00:0\n",
      "epoch 3 - val Loss: 8.369e+01 - val Acc: 16.00%: 100%|█| 98/98 [00:02<00:00, 35.\n",
      "epoch 4 - train Loss: 9.920e+03 - train Acc: 59.12%: 100%|█| 293/293 [00:21<00:0\n",
      "epoch 4 - val Loss: 8.369e+01 - val Acc: 16.00%: 100%|█| 98/98 [00:03<00:00, 28.\n",
      "epoch 5 - train Loss: 1.005e+04 - train Acc: 58.56%: 100%|█| 293/293 [00:23<00:0\n",
      "epoch 5 - val Loss: 8.369e+01 - val Acc: 16.00%: 100%|█| 98/98 [00:03<00:00, 29.\n",
      "epoch 6 - train Loss: 9.927e+03 - train Acc: 58.97%:  85%|▊| 250/293 [00:19<00:0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28094/2449094383.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0moptimizer2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/generalAI/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    189\u001b[0m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m                         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/generalAI/lib/python3.9/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0mrelevant_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelevant_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m             \u001b[0;31m# TODO mypy doesn't support @property, see: https://github.com/python/mypy/issues/6185\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelevant_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/generalAI/lib/python3.9/site-packages/torch/overrides.py\u001b[0m in \u001b[0;36mhas_torch_function\u001b[0;34m(relevant_args)\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \u001b[0mimplementations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \"\"\"\n\u001b[0;32m-> 1083\u001b[0;31m     return _is_torch_function_enabled() and any(\n\u001b[0m\u001b[1;32m   1084\u001b[0m         \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__torch_function__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_disabled_torch_function_impl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "all_train_losses = []\n",
    "all_train_accuracy = []\n",
    "all_val_losses = []\n",
    "all_val_accuracy = []\n",
    "for epoch in range(NUMBER_OF_EPOCHS2):\n",
    "    # training\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    acc_list = []\n",
    "    epoch_all = 0\n",
    "    model.train()\n",
    "    with tqdm.tqdm(enumerate(train_loader), total=len(train_loader)) as pbar:\n",
    "        for i, (x1,x2, y) in pbar:\n",
    "            optimizer2.zero_grad()\n",
    "            outputs = model2(x1,x2)\n",
    "            loss = loss_function2(outputs , y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += outputs.shape[0] * loss.item()\n",
    "            epoch_all += y.size(0)\n",
    "            predicted = torch.floor(outputs)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            pbar.set_description(f'epoch {epoch } - train Loss: {epoch_loss / (i + 1):.3e} - train Acc: {correct * 100. / epoch_all:.2f}%')\n",
    "    loss_list = []\n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        main = []\n",
    "        pre = []\n",
    "        epoch_loss = 0\n",
    "        epoch_all = 0\n",
    "        correct = 0\n",
    "        corr = 0\n",
    "        tot = 0\n",
    "        with tqdm.tqdm(enumerate(val_loader), total=len(val_loader)) as pbar:\n",
    "            for i, (x1,x2, y) in pbar:\n",
    "                out = model2(x1,x2)\n",
    "                los = loss_function2(out , y).item()\n",
    "                main.append(y)\n",
    "                epoch_loss += los\n",
    "                loss_list.append(los)\n",
    "                predicts = torch.floor(out)\n",
    "                pre.append(predicts)\n",
    "                epoch_all+=y.size(0)\n",
    "                tot += y.size(0)\n",
    "                correct += (predicts == y).sum().item()\n",
    "                pbar.set_description(f'epoch {epoch } - val Loss: {epoch_loss / (i + 1):.3e} - val Acc: {correct * 100. / epoch_all:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
